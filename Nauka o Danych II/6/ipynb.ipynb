{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9521d-5c33-43c9-89b9-5ab5b1438e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Dane: zapotrzebowanie na energię (kWh)\n",
    "np.random.seed(0)\n",
    "days = 365\n",
    "t = np.arange(days)\n",
    "energy = 200 + 30*np.sin(2 * np.pi * t / 30) + 10*np.cos(2 * np.pi * t / 7) + np.random.normal(0, 5, days)\n",
    "energy = energy.reshape(-1, 1)\n",
    "\n",
    "# Normalizacja\n",
    "scaler = MinMaxScaler()\n",
    "energy_scaled = scaler.fit_transform(energy)\n",
    "\n",
    "# Przygotowanie sekwencji\n",
    "def create_sequences(data, look_back=14):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:i+look_back])\n",
    "        y.append(data[i+look_back])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "look_back = 14\n",
    "X, y = create_sequences(energy_scaled, look_back)\n",
    "\n",
    "# Model LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=15, batch_size=8, verbose=1)\n",
    "\n",
    "# Prognoza\n",
    "predicted = model.predict(X)\n",
    "predicted_inv = scaler.inverse_transform(predicted)\n",
    "real_inv = scaler.inverse_transform(y)\n",
    "\n",
    "# Wykres\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(real_inv, label='Rzeczywiste')\n",
    "plt.plot(predicted_inv, label='Prognozowane')\n",
    "plt.title(\"Prognoza zapotrzebowania na energię (kWh)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca1552-39ca-4bf9-b4fc-a881f5978326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Hubert\\Programy\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9028 - loss: 0.5401 - val_accuracy: 0.8850 - val_loss: 0.4308\n",
      "Epoch 2/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.3812 - val_accuracy: 0.8850 - val_loss: 0.3200\n",
      "Epoch 3/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2715 - val_accuracy: 0.8850 - val_loss: 0.1895\n",
      "Epoch 4/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.1293 - val_accuracy: 1.0000 - val_loss: 0.0606\n",
      "Epoch 5/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0368 - val_accuracy: 1.0000 - val_loss: 0.0236\n",
      "Epoch 6/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0145\n",
      "Epoch 7/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0107\n",
      "Epoch 8/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 1.0000 - val_loss: 0.0084\n",
      "Epoch 9/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 1.0000 - val_loss: 0.0069\n",
      "Epoch 10/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0059\n",
      "Epoch 11/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 12/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 13/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 14/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 15/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Dokładność wykrywania anomalii: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Krok 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Dane: normalne i anormalne zużycie prądu\n",
    "def generate_power_data(n=1000, timesteps=10):\n",
    "    X = np.random.normal(1.0, 0.1, (n, timesteps))  # normalny pobór\n",
    "    y = np.zeros(n)\n",
    "    anomalies = np.random.choice(n, n // 10, replace=False)\n",
    "    X[anomalies] += np.random.normal(1.5, 0.5, (len(anomalies), timesteps))  # anomalie\n",
    "    y[anomalies] = 1\n",
    "    return X.reshape(n, timesteps, 1), y\n",
    "\n",
    "X, y = generate_power_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X.shape[1], 1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Ocena\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Dokładność wykrywania anomalii: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f824161-dcfc-48ca-a5dd-549b73bebbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8374 - loss: 0.9212 - val_accuracy: 0.6333 - val_loss: 0.4189\n",
      "Epoch 2/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9374 - loss: 0.2382 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "Epoch 3/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 4/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 5/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 9.8712e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4714e-04 - val_accuracy: 1.0000 - val_loss: 8.0842e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.8742e-04 - val_accuracy: 1.0000 - val_loss: 6.7715e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.5139e-04 - val_accuracy: 1.0000 - val_loss: 5.7737e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.6097e-04 - val_accuracy: 1.0000 - val_loss: 4.9935e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9192e-04 - val_accuracy: 1.0000 - val_loss: 4.3689e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.2812e-04 - val_accuracy: 1.0000 - val_loss: 3.8607e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.7843e-04 - val_accuracy: 1.0000 - val_loss: 3.4463e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 3.3653e-04 - val_accuracy: 1.0000 - val_loss: 3.0926e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.0496e-04 - val_accuracy: 1.0000 - val_loss: 2.7958e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7798e-04 \n",
      "Dokładność klasyfikacji urządzeń: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Krok 3\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Symulacja: 0 - lodówka, 1 - klimatyzacja, 2 - pralka\n",
    "def generate_device_data(samples=1500, timesteps=30):\n",
    "    X, y = [], []\n",
    "    for label in range(3):\n",
    "        for _ in range(samples // 3):\n",
    "            if label == 0:\n",
    "                seq = np.random.normal(0.5, 0.05, timesteps)  # lodówka - stałe zużycie\n",
    "            elif label == 1:\n",
    "                seq = np.sin(np.linspace(0, 2*np.pi, timesteps)) + np.random.normal(0, 0.1, timesteps)  # klima - cykle\n",
    "            else:\n",
    "                seq = np.concatenate([\n",
    "                    np.zeros(timesteps//3),\n",
    "                    np.random.normal(1.0, 0.2, timesteps//3),\n",
    "                    np.zeros(timesteps//3)\n",
    "                ])  # pralka - bursty\n",
    "            X.append(seq)\n",
    "            y.append(label)\n",
    "    return np.array(X).reshape(-1, timesteps, 1), to_categorical(np.array(y), 3)\n",
    "\n",
    "X, y = generate_device_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model klasyfikacyjny\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X.shape[1], 1)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Ocena\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Dokładność klasyfikacji urządzeń: {acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
