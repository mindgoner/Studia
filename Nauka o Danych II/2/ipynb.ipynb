{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdcacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 1: Import bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbce2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 2: Wczytanie danych\n",
    "df = pd.read_csv(\"synthetic_health_data.csv\")\n",
    "X = df[[\"wiek\", \"BMI\", \"aktywnosc\", \"kalorie\", \"sen\"]]\n",
    "y = df[[\"cukier\", \"cisnienie_skurczowe\", \"cisnienie_rozkurczowe\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa42f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 3: Podział danych na treningowe i testowe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cea3b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 4: Definicja modeli bazowych\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "stack = StackingRegressor(\n",
    "    estimators=[('rf', rf), ('xgb', xgb)],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211c2e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest średni R²: 0.7685\n",
      "XGBoost średni R²: 0.7548\n",
      "Stacking średni R²: 0.7717\n"
     ]
    }
   ],
   "source": [
    "# Krok 5: Trenowanie i ewaluacja modeli (dla każdej zmiennej osobno)\n",
    "results = {}\n",
    "\n",
    "targets = [\"cukier\", \"cisnienie_skurczowe\", \"cisnienie_rozkurczowe\"]\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = []\n",
    "    for target in targets:\n",
    "        model.fit(X_train, y_train[target])\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test[target], y_pred)\n",
    "        scores.append(r2)\n",
    "    avg_r2 = np.mean(scores)\n",
    "    results[name] = avg_r2\n",
    "    print(f\"{name} średni R²: {avg_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92216f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepszy XGBoost: {'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Krok 6: Tuning hiperparametrów dla XGBoost\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [3, 5, 7]\n",
    "}\n",
    "grid = GridSearchCV(XGBRegressor(random_state=42), param_grid, cv=3, scoring='r2')\n",
    "grid.fit(X_train, y_train)\n",
    "best_xgb = grid.best_estimator_\n",
    "print(\"Najlepszy XGBoost:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a909190",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (8000, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Krok 7: Dodanie nowego modelu do stackingu (np. KNN)\u001b[39;00m\n\u001b[32m      2\u001b[39m stack2 = StackingRegressor(\n\u001b[32m      3\u001b[39m     estimators=[\n\u001b[32m      4\u001b[39m         (\u001b[33m'\u001b[39m\u001b[33mrf\u001b[39m\u001b[33m'\u001b[39m, rf),\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     final_estimator=LinearRegression()\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mstack2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m y_pred_stack2 = stack2.predict(X_test)\n\u001b[32m     13\u001b[39m r2_stack2 = r2_score(y_test, y_pred_stack2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programs\\Python\\3.11\\Lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[39m, in \u001b[36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     66\u001b[39m args_msg = [\n\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     69\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programs\\Python\\3.11\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:1060\u001b[39m, in \u001b[36mStackingRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[32m   1029\u001b[39m \n\u001b[32m   1030\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1057\u001b[39m \u001b[33;03m    Returns a fitted instance.\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1059\u001b[39m _raise_for_params(fit_params, \u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m y = \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1062\u001b[39m     fit_params[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Programs\\Python\\3.11\\Lib\\site-packages\\sklearn\\utils\\validation.py:1485\u001b[39m, in \u001b[36mcolumn_or_1d\u001b[39m\u001b[34m(y, dtype, warn, device)\u001b[39m\n\u001b[32m   1472\u001b[39m         warnings.warn(\n\u001b[32m   1473\u001b[39m             (\n\u001b[32m   1474\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mA column-vector y was passed when a 1d array was\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1479\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1480\u001b[39m         )\n\u001b[32m   1481\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(\n\u001b[32m   1482\u001b[39m         xp.reshape(y, (-\u001b[32m1\u001b[39m,)), order=\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, xp=xp, device=device\n\u001b[32m   1483\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1485\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1486\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m.format(shape)\n\u001b[32m   1487\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: y should be a 1d array, got an array of shape (8000, 3) instead."
     ]
    }
   ],
   "source": [
    "# Krok 7: Dodanie nowego modelu do stackingu (np. KNN)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "targets = [\"cukier\", \"cisnienie_skurczowe\", \"cisnienie_rozkurczowe\"]\n",
    "r2_scores_stack2 = []\n",
    "\n",
    "for target in targets:\n",
    "    stack2 = StackingRegressor(\n",
    "        estimators=[\n",
    "            ('rf', rf),\n",
    "            ('xgb', best_xgb),\n",
    "            ('knn', KNeighborsRegressor())\n",
    "        ],\n",
    "        final_estimator=LinearRegression()\n",
    "    )\n",
    "    \n",
    "    stack2.fit(X_train, y_train[target])\n",
    "    y_pred = stack2.predict(X_test)\n",
    "    r2 = r2_score(y_test[target], y_pred)\n",
    "    r2_scores_stack2.append(r2)\n",
    "\n",
    "avg_r2_stack2 = np.mean(r2_scores_stack2)\n",
    "results[\"Stacking + KNN\"] = avg_r2_stack2\n",
    "print(f\"Stacking + KNN średni R² score: {avg_r2_stack2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de202a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 8: Testowanie modeli na zbiorze danych Wine\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "X_wine = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "y_wine = pd.DataFrame(wine.target)\n",
    "\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(X_wine, y_wine, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ponieważ mamy klasyfikację, przetestujemy XGBoost jako klasyfikator\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=42)\n",
    "clf_xgb = XGBClassifier(random_state=42)\n",
    "clf_stack = StackingClassifier(\n",
    "    estimators=[('rf', clf_rf), ('xgb', clf_xgb)],\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "clf_models = {\n",
    "    \"Random Forest (wine)\": clf_rf,\n",
    "    \"XGBoost (wine)\": clf_xgb,\n",
    "    \"Stacking (wine)\": clf_stack\n",
    "}\n",
    "\n",
    "for name, clf in clf_models.items():\n",
    "    clf.fit(Xw_train, yw_train.values.ravel())\n",
    "    y_pred = clf.predict(Xw_test)\n",
    "    acc = accuracy_score(yw_test, y_pred)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Krok 9: Wykres porównujący dokładność/R² modeli\n",
    "plt.figure(figsize=(10, 6))\n",
    "labels = list(results.keys())\n",
    "scores = list(results.values())\n",
    "\n",
    "plt.barh(labels, scores)\n",
    "plt.xlabel(\"R² (dla regresji) / Accuracy (dla klasyfikacji)\")\n",
    "plt.title(\"Porównanie skuteczności modeli\")\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
